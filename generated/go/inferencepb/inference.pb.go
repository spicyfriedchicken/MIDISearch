// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v5.29.3
// source: inference.proto

package inferencepb

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type StatusCode int32

const (
	StatusCode_STATUS_OK              StatusCode = 0
	StatusCode_STATUS_ERROR           StatusCode = 1
	StatusCode_STATUS_INVALID_INPUT   StatusCode = 2
	StatusCode_STATUS_MODEL_NOT_FOUND StatusCode = 3
	StatusCode_STATUS_TIMEOUT         StatusCode = 4
)

// Enum value maps for StatusCode.
var (
	StatusCode_name = map[int32]string{
		0: "STATUS_OK",
		1: "STATUS_ERROR",
		2: "STATUS_INVALID_INPUT",
		3: "STATUS_MODEL_NOT_FOUND",
		4: "STATUS_TIMEOUT",
	}
	StatusCode_value = map[string]int32{
		"STATUS_OK":              0,
		"STATUS_ERROR":           1,
		"STATUS_INVALID_INPUT":   2,
		"STATUS_MODEL_NOT_FOUND": 3,
		"STATUS_TIMEOUT":         4,
	}
)

func (x StatusCode) Enum() *StatusCode {
	p := new(StatusCode)
	*p = x
	return p
}

func (x StatusCode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (StatusCode) Descriptor() protoreflect.EnumDescriptor {
	return file_inference_proto_enumTypes[0].Descriptor()
}

func (StatusCode) Type() protoreflect.EnumType {
	return &file_inference_proto_enumTypes[0]
}

func (x StatusCode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use StatusCode.Descriptor instead.
func (StatusCode) EnumDescriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{0}
}

type InferenceRequest struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	JobId            string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`                                                                    // unique job_id toward the router
	ModelName        string                 `protobuf:"bytes,2,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`                                                        // get model_name
	InputData        []byte                 `protobuf:"bytes,3,opt,name=input_data,json=inputData,proto3" json:"input_data,omitempty"`                                                        // raw bytes for our image/video/audio (just image for now)
	Metadata         map[string]string      `protobuf:"bytes,4,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // associated metadata, resolution, etc.
	ContentType      string                 `protobuf:"bytes,5,opt,name=content_type,json=contentType,proto3" json:"content_type,omitempty"`                                                  // "image/png", "audio/wav", going to remain .png for now
	RequestTimestamp int64                  `protobuf:"varint,6,opt,name=request_timestamp,json=requestTimestamp,proto3" json:"request_timestamp,omitempty"`                                  // unix epoch milliseconds for request to gauge perf
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *InferenceRequest) Reset() {
	*x = InferenceRequest{}
	mi := &file_inference_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceRequest) ProtoMessage() {}

func (x *InferenceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceRequest.ProtoReflect.Descriptor instead.
func (*InferenceRequest) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{0}
}

func (x *InferenceRequest) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

func (x *InferenceRequest) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *InferenceRequest) GetInputData() []byte {
	if x != nil {
		return x.InputData
	}
	return nil
}

func (x *InferenceRequest) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferenceRequest) GetContentType() string {
	if x != nil {
		return x.ContentType
	}
	return ""
}

func (x *InferenceRequest) GetRequestTimestamp() int64 {
	if x != nil {
		return x.RequestTimestamp
	}
	return 0
}

type InferenceResponse struct {
	state             protoimpl.MessageState `protogen:"open.v1"`
	JobId             string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`                                                                                          // mirrors request's job_id
	OutputData        []byte                 `protobuf:"bytes,2,opt,name=output_data,json=outputData,proto3" json:"output_data,omitempty"`                                                                           // final result (e.g. upscaled image)
	OutputMeta        map[string]string      `protobuf:"bytes,3,rep,name=output_meta,json=outputMeta,proto3" json:"output_meta,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"` // mirrors metadata, but with new resolution
	StatusCode        StatusCode             `protobuf:"varint,4,opt,name=status_code,json=statusCode,proto3,enum=inference.StatusCode" json:"status_code,omitempty"`                                                // enum: more explicit than raw int
	ErrorMessage      string                 `protobuf:"bytes,5,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`                                                                     // optional if status_code != OK
	ResponseTimestamp int64                  `protobuf:"varint,6,opt,name=response_timestamp,json=responseTimestamp,proto3" json:"response_timestamp,omitempty"`                                                     // unix epoch millis for response to gauge perf
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *InferenceResponse) Reset() {
	*x = InferenceResponse{}
	mi := &file_inference_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceResponse) ProtoMessage() {}

func (x *InferenceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_inference_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceResponse.ProtoReflect.Descriptor instead.
func (*InferenceResponse) Descriptor() ([]byte, []int) {
	return file_inference_proto_rawDescGZIP(), []int{1}
}

func (x *InferenceResponse) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

func (x *InferenceResponse) GetOutputData() []byte {
	if x != nil {
		return x.OutputData
	}
	return nil
}

func (x *InferenceResponse) GetOutputMeta() map[string]string {
	if x != nil {
		return x.OutputMeta
	}
	return nil
}

func (x *InferenceResponse) GetStatusCode() StatusCode {
	if x != nil {
		return x.StatusCode
	}
	return StatusCode_STATUS_OK
}

func (x *InferenceResponse) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

func (x *InferenceResponse) GetResponseTimestamp() int64 {
	if x != nil {
		return x.ResponseTimestamp
	}
	return 0
}

var File_inference_proto protoreflect.FileDescriptor

const file_inference_proto_rawDesc = "" +
	"\n" +
	"\x0finference.proto\x12\tinference\"\xbb\x02\n" +
	"\x10InferenceRequest\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\x12\x1d\n" +
	"\n" +
	"model_name\x18\x02 \x01(\tR\tmodelName\x12\x1d\n" +
	"\n" +
	"input_data\x18\x03 \x01(\fR\tinputData\x12E\n" +
	"\bmetadata\x18\x04 \x03(\v2).inference.InferenceRequest.MetadataEntryR\bmetadata\x12!\n" +
	"\fcontent_type\x18\x05 \x01(\tR\vcontentType\x12+\n" +
	"\x11request_timestamp\x18\x06 \x01(\x03R\x10requestTimestamp\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xe5\x02\n" +
	"\x11InferenceResponse\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\x12\x1f\n" +
	"\voutput_data\x18\x02 \x01(\fR\n" +
	"outputData\x12M\n" +
	"\voutput_meta\x18\x03 \x03(\v2,.inference.InferenceResponse.OutputMetaEntryR\n" +
	"outputMeta\x126\n" +
	"\vstatus_code\x18\x04 \x01(\x0e2\x15.inference.StatusCodeR\n" +
	"statusCode\x12#\n" +
	"\rerror_message\x18\x05 \x01(\tR\ferrorMessage\x12-\n" +
	"\x12response_timestamp\x18\x06 \x01(\x03R\x11responseTimestamp\x1a=\n" +
	"\x0fOutputMetaEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01*w\n" +
	"\n" +
	"StatusCode\x12\r\n" +
	"\tSTATUS_OK\x10\x00\x12\x10\n" +
	"\fSTATUS_ERROR\x10\x01\x12\x18\n" +
	"\x14STATUS_INVALID_INPUT\x10\x02\x12\x1a\n" +
	"\x16STATUS_MODEL_NOT_FOUND\x10\x03\x12\x12\n" +
	"\x0eSTATUS_TIMEOUT\x10\x042V\n" +
	"\x10InferenceService\x12B\n" +
	"\x05Infer\x12\x1b.inference.InferenceRequest\x1a\x1c.inference.InferenceResponseB\x0eZ\f/inferencepbb\x06proto3"

var (
	file_inference_proto_rawDescOnce sync.Once
	file_inference_proto_rawDescData []byte
)

func file_inference_proto_rawDescGZIP() []byte {
	file_inference_proto_rawDescOnce.Do(func() {
		file_inference_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_inference_proto_rawDesc), len(file_inference_proto_rawDesc)))
	})
	return file_inference_proto_rawDescData
}

var file_inference_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_inference_proto_msgTypes = make([]protoimpl.MessageInfo, 4)
var file_inference_proto_goTypes = []any{
	(StatusCode)(0),           // 0: inference.StatusCode
	(*InferenceRequest)(nil),  // 1: inference.InferenceRequest
	(*InferenceResponse)(nil), // 2: inference.InferenceResponse
	nil,                       // 3: inference.InferenceRequest.MetadataEntry
	nil,                       // 4: inference.InferenceResponse.OutputMetaEntry
}
var file_inference_proto_depIdxs = []int32{
	3, // 0: inference.InferenceRequest.metadata:type_name -> inference.InferenceRequest.MetadataEntry
	4, // 1: inference.InferenceResponse.output_meta:type_name -> inference.InferenceResponse.OutputMetaEntry
	0, // 2: inference.InferenceResponse.status_code:type_name -> inference.StatusCode
	1, // 3: inference.InferenceService.Infer:input_type -> inference.InferenceRequest
	2, // 4: inference.InferenceService.Infer:output_type -> inference.InferenceResponse
	4, // [4:5] is the sub-list for method output_type
	3, // [3:4] is the sub-list for method input_type
	3, // [3:3] is the sub-list for extension type_name
	3, // [3:3] is the sub-list for extension extendee
	0, // [0:3] is the sub-list for field type_name
}

func init() { file_inference_proto_init() }
func file_inference_proto_init() {
	if File_inference_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_inference_proto_rawDesc), len(file_inference_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   4,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_inference_proto_goTypes,
		DependencyIndexes: file_inference_proto_depIdxs,
		EnumInfos:         file_inference_proto_enumTypes,
		MessageInfos:      file_inference_proto_msgTypes,
	}.Build()
	File_inference_proto = out.File
	file_inference_proto_goTypes = nil
	file_inference_proto_depIdxs = nil
}
